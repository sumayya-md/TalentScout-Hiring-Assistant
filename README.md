ğŸ¤– TalentScout â€” Hiring Assistant Chatbot (Streamlit)
An intelligent screening assistant for tech roles. It collects candidate details and generates tailored technical questions from the candidateâ€™s declared tech stack using an LLM (OpenAI by default). Falls back to a deterministic offline generator if no API key is set.

âœ¨ Features
Friendly greeting + clear purpose

Step-by-step information gathering (name, email, phone, years of experience, desired role, location, tech stack)

3â€“5 tailored technical questions based on the declared stack

Context-aware flow with validation and a fallback mechanism

Conversation exit keywords: end, exit, quit, bye

Privacy-first storage: only salted hashes of email/phone are saved for deduping; no plaintext PII persisted

Export JSON record of the conversation (candidate + questions)

Clean Streamlit UI with session management

ğŸš€ Installation & Setup
bash
Copy
Edit
# Clone the repository
git clone https://github.com/yourusername/talentscout-chatbot.git
cd talentscout-chatbot

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py
ğŸ”‘ Note:

To use LLM-powered question generation, set your OPENAI_API_KEY as an environment variable.

Without a key, the chatbot will fall back to built-in static questions.

ğŸ–¥ï¸ Usage Guide
Open the app in your browser after running streamlit run app.py.

The chatbot will greet you and explain its purpose.

Provide details step by step:

Full Name

Email Address

Phone Number

Years of Experience

Desired Position(s)

Current Location

Tech Stack (languages, frameworks, tools)

Receive tailored technical questions based on your stack.

Type end / exit / bye to gracefully conclude the conversation.

âš™ï¸ Tech Stack
Python

Streamlit (UI)

OpenAI API / fallback logic (LLM-powered question generation)

JSON storage for conversation export

ğŸ§‘â€ğŸ’» Prompt Design
Information Gathering Prompt â†’ Collects candidate info in a structured way.

Tech Stack Prompt â†’ Maps declared skills to specific question templates.

Contextual Follow-ups â†’ Ensures smooth flow of the interview.

Fallback Handling â†’ Returns helpful clarifications if input is unclear.

ğŸ† Challenges & Solutions
Context Handling â†’ Solved using Streamlit st.session_state to persist data.

Data Privacy â†’ Instead of saving raw PII, only hashed identifiers are stored.

No API Key Case â†’ Implemented offline static generator for robustness.

ğŸ“¹ Demo
Loom/Video link here (if recorded)

Or include screenshots in /demo/ folder

ğŸ“‚ Repository Structure
bash
Copy
Edit
â”œâ”€â”€ app.py                 # Main Streamlit app
â”œâ”€â”€ prompts.py             # Prompt templates
â”œâ”€â”€ utils.py               # Helper functions (hashing, fallback Qs)
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ demo/                  # Screenshots or video link (optional)
ğŸ“œ License
For educational/demo purposes only.